# -*- coding: utf-8 -*-
"""wav2vec_layer_12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rYPLgl6fINQnbQrWZVSQWP3KTRkTfbDV
"""

from google.colab import drive

drive.mount("/content/drive")

"""## Imports

"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder

from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score, classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import SelectKBest, f_classif

import xgboost as xgb
from catboost import CatBoostClassifier

import matplotlib.pyplot as plt
import seaborn as sn

from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, randint

import time

"""## Load dataset and create dataframes

"""

# Load datasets
train_df = pd.read_csv("../datasets/layer-12/train.csv")
valid_df = pd.read_csv("../datasets/layer-12/valid.csv")
test_df = pd.read_csv("../datasets/layer-12/test.csv")

train_df.shape, valid_df.shape, test_df.shape

"""## For each label, seperate feature data

"""

labels = ["label_1", "label_2", "label_3", "label_4"]

X_train = {}
X_valid = {}
X_test = {}
y_train = {}
y_valid = {}

for label in labels:
    # Standardize the feature columns
    scaler = StandardScaler()
    tr_df = train_df
    val_df = valid_df
    tst_df = test_df
    if label == "label_2":  # Remove NaN rows for label_2
        tr_df = train_df[train_df[label].notna()]
        val_df = valid_df[valid_df[label].notna()]

    X_train[label] = pd.DataFrame(scaler.fit_transform(tr_df.iloc[:, :-4]))
    X_valid[label] = pd.DataFrame(scaler.transform(val_df.iloc[:, :-4]))
    X_test[label] = pd.DataFrame(scaler.transform(tst_df.iloc[:, 1:]))

    # Ensure you keep the target labels as separate DataFrames
    y_train[label] = tr_df[label]
    y_valid[label] = val_df[label]

"""## Feature Selection

"""

X_train_selected = {}
X_valid_selected = {}
X_test_selected = {}

"""Feature selection for each label

"""

def feature_selection(L):
    # Figure label frequencies
    plt.figure(figsize=(15, 6))
    sn.countplot(data=y_train, x=L, color="green")

    k = (
        350
        if L == labels[0]
        else (350 if L == labels[1] else 350 if L == labels[3] else 350)
    )

    selector = SelectKBest(f_classif, k=k)

    X_train_selected[L] = pd.DataFrame(
        selector.fit_transform(X_train[label], y_train[label])
    )
    X_valid_selected[L] = pd.DataFrame(selector.transform(X_valid[label]))
    X_test_selected[L] = pd.DataFrame(selector.transform(X_test[label]))

for label in labels:
    feature_selection(label)

X_train_selected["label_1"].shape

X_valid_selected["label_1"].shape

X_test_selected["label_3"].shape

"""## Dimensionality reduction using PCA

"""

X_train_pca = {}
X_valid_pca = {}
X_test_pca = {}

from sklearn.decomposition import PCA


def PCA_reduction(L, X_train, X_valid):
    n_components = 0.99 if L == labels[1] else 0.95

    # Fit PCA on the training data
    pca = PCA(n_components=n_components)
    X_train_pca[L] = pca.fit_transform(X_train[L])

    # Transform validation and test data using the same PCA
    X_valid_pca[L] = pca.transform(X_valid[L])
    X_test_pca[L] = pca.transform(X_test[L])

for label in labels:
    PCA_reduction(label, X_train, X_valid)

X_train_pca["label_2"].shape

"""## Classifier Models

"""

models = ["svm", "xgb", "catboost"]

def classifier(model, L, X_train, X_valid, y_train, y_valid):
    classifier = None
    class_weight = None if L == labels[0] else "balanced"

    if model == models[0]:
        # Create an SVM classifier
        classifier = SVC(kernel="linear", class_weight=class_weight)
    elif model == models[1]:
        # Create an XGBoost classifier
        classifier = xgb.XGBClassifier()
        # Encode the target variable if needed
        label_encoder = LabelEncoder()
        y = label_encoder.fit_transform(y)
        y_train[L] = y_train[L] - 1
    elif model == models[2]:
        # Create an random forest classifier
        classifier = CatBoostClassifier()

    classifier.fit(X_train[L], y_train[L])

    y_pred = classifier.predict(X_valid[L])
    accuracy = accuracy_score(y_valid[L], y_pred)
    print(f"{model} Accuracy Score for {L} = ", accuracy)

    return classifier

"""## Cross validation

"""

def cross_validation(model, L, X, y, catboostIterations=10):
    classifier = None
    class_weight = None if L == labels[0] else "balanced"

    if model == models[0]:
        # Create an SVM classifier
        classifier = SVC(kernel="rbf", class_weight=class_weight)
    elif model == models[1]:
        # Create an XGBoost classifier
        classifier = xgb.XGBClassifier()
        # Encode the target variable if needed
        label_encoder = LabelEncoder()
        y = label_encoder.fit_transform(y)
    elif model == models[2]:
        # Create an random forest classifier
        classifier = CatBoostClassifier(iterations=catboostIterations)

    # Perform 5-fold cross-validation
    print(f"5-fold cross validation started for {model}")
    scores = cross_val_score(classifier, X, y, cv=5)
    print(f"5-fold cross validation finished")

    # Print the cross-validation scores
    print("Cross-Validation Scores:", scores)

    # Calculate and print the mean and standard deviation of the scores
    mean_score = np.mean(scores)
    std_deviation = np.std(scores)
    print("Mean Score:", mean_score)
    print("Standard Deviation:", std_deviation)

"""Cross Validation for SVM

"""

for label in labels:
    cross_validation(models[0], label, X_train[label], y_train[label])
    print("\n")

"""SVM Cross Validation Results:

5-fold cross validation started for svm
5-fold cross validation finished
Cross-Validation Scores: [0.9200561 0.9154979 0.91304348 0.91619916 0.91374474]
Mean Score: 0.9157082748948107
Standard Deviation: 0.0024554195511937785

5-fold cross validation started for svm
5-fold cross validation finished
Cross-Validation Scores: [0.37642653 0.55313837 0.603602 0.57703281 0.43099144]
Mean Score: 0.5082382310984308
Standard Deviation: 0.08852610353781822

5-fold cross validation started for svm
5-fold cross validation finished
Cross-Validation Scores: [0.97124825 0.98807854 0.98229313 0.98176718 0.99140954]
Mean Score: 0.9829593267882186
Standard Deviation: 0.006879343572650934

5-fold cross validation started for svm
5-fold cross validation finished
Cross-Validation Scores: [0.86079944 0.83888499 0.81854839 0.84940393 0.80908135]
Mean Score: 0.8353436185133241
Standard Deviation: 0.019131226513951945

Cross Validation for Catboost with 10 iterations
"""

for label in labels:
    cross_validation(models[2], label, X_train[label], y_train[label], 10)
    print("\n")

# With 1000 ietrations for label 3
cross_validation(models[2], labels[2], X_train[labels[2]], y_train[labels[2]], 1000)

# With 100 ietrations for label 2
cross_validation(models[2], labels[1], X_train[labels[1]], y_train[labels[1]], 100)

"""Cross validation for XGBoost

"""

cross_validation(models[1], labels[0], X_train[labels[0]], y_train[labels[0]])

cross_validation(models[1], labels[1], X_train[labels[1]], y_train[labels[1]])

cross_validation(models[1], labels[2], X_train[labels[2]], y_train[labels[2]])

cross_validation(models[1], labels[3], X_train[labels[3]], y_train[labels[3]])

"""## Hyperparameter Tuning

"""

# Model hyperparameters
param_dist_svm = {
    "C": np.logspace(-3, 3, 6),
    "kernel": ["linear", "rbf", "poly"],
    "gamma": ["scale", "auto"] + list(np.logspace(-3, 3, 5)),
}

param_dist_xgboost = {
    "learning_rate": uniform(0.01, 0.3),
    "n_estimators": randint(50, 200),
    "max_depth": randint(1, 10),
    "min_child_weight": randint(1, 10),
}

param_dist_random_forest = {
    "n_estimators": randint(50, 200),
    "max_depth": randint(1, 20),
    "min_samples_split": randint(2, 20),
    "min_samples_leaf": randint(1, 20),
}

def best_classifier(model, L, X_train, X_valid, y_train, y_valid, random_state, n_iter, n_jobs, cv=2):
    t1 = time.time()
    classifier = None
    class_weight = None if L == labels[0] else "balanced"
    param_dist = None

    if model == models[0]:
        # Create an SVM classifier
        classifier = SVC(kernel="linear", class_weight=class_weight)
        param_dist = param_dist_svm
    elif model == models[1]:
        # Create an XGBoost classifier
        classifier = xgb.XGBClassifier()
        param_dist = param_dist_xgboost
    elif model == models[2]:
        # Create an random forest classifier
        classifier = RandomForestClassifier()
        param_dist = param_dist_random_forest

    # Perform Random Search for each model
    random_search = RandomizedSearchCV(
        classifier,
        param_distributions=param_dist,
        scoring="accuracy",
        cv=cv,
        verbose=1,
        random_state=random_state,
        n_iter=n_iter,
        n_jobs=n_jobs,
    )
    print(
        "===========================Random search fit started================================"
    )
    random_search.fit(X_train[L], y_train[L])
    print(
        "===========================Random search fit stopped================================"
    )
    classifier = random_search.best_estimator_  # Get best classifier from random search
    print(f"Best Parameters for {model}:")
    print(random_search.best_params_)
    print(f"Best Accuracy for {model}:")
    print(random_search.best_score_)

    classifier.fit(X_train[L], y_train[L])

    y_pred = classifier.predict(X_valid[L])
    accuracy = accuracy_score(y_valid[L], y_pred)
    print(f"{model} Accuracy Score for {L} = ", accuracy)

    t2 = time.time()
    print(f"Time elapsed: {(t2-t1)/60}mins")

    return classifier

"""SVM Model Evaluation after hyperparameter tuning

`cv=2`

`random_state=42`

`n_jobs=1`

"""

l1_best_model = best_classifier(
    models[0], labels[0], X_train_pca, X_valid_pca, y_train, y_valid, random_state=42, n_iter=5, n_jobs=1
)

l2_best_model = best_classifier(
    models[0], labels[1], X_train_pca, X_valid_pca, y_train, y_valid, random_state=42, n_iter=5, n_jobs=1
)

l3_best_model = best_classifier(
    models[0], labels[2], X_train_pca, X_valid_pca, y_train, y_valid, random_state=42, n_iter=5, n_jobs=1
)

l4_best_model = best_classifier(
    models[0], labels[3], X_train_pca, X_valid_pca, y_train, y_valid, random_state=42, n_iter=5, n_jobs=1
)